{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125c219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/04 02:39:15 INFO mlflow.utils.credentials: Successfully connected to MLflow hosted tracking server! Host: https://dbc-7d1169bb-4536.cloud.databricks.com.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Connect to Databricks workspace with submitted credentials or use stored credentials\n",
    "mlflow.login()\n",
    "# Set tracking URI to Databricks -  tell MLflow to send the data into Databricks Workspace\n",
    "mlflow.set_tracking_uri(\"databricks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1ce258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source /mnt/e/Projekti/ml/databricks-timeseries/.venv/bin/activate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:code_model_950a1fbba0f64d34b8efd894fd65dfba:Initializing ToolCallingAgentNoMemory with model: gpt-5-nano\n",
      "2025/11/04 02:39:33 INFO mlflow.pyfunc: Predicting on input example to validate output\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:code_model_950a1fbba0f64d34b8efd894fd65dfba:Last message type: message and role: user\n",
      "INFO:code_model_950a1fbba0f64d34b8efd894fd65dfba:Calling LLM with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can call tools to get information.'}, {'status': None, 'content': 'What is the full name of poet Byron?', 'role': 'user', 'type': 'message'}]\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:code_model_950a1fbba0f64d34b8efd894fd65dfba:LLM output: [ResponseReasoningItem(id='rs_0efdc0313798afdf016909595d44a0819392230ffeda70080b', summary=[Summary(text='**Providing Byron\\'s full name**\\n\\nI need to answer the question about Lord Byron\\'s full name. That\\'s George Gordon Byron, 6th Baron Byron. Heâ€™s commonly known as simply George Gordon Byron or Lord Byron. The explicit full name is George Gordon Byron, so Iâ€™ll keep it clear and concise. I could add his title if needed, but since the user just asked for the full name, I\\'ll stick with: George Gordon Byron (6th Baron Byron). No additional details are necessary!**Clarifying Byron\\'s full name**\\n\\nI want to make sure thereâ€™s no confusion about Lord Byronâ€™s name. Some sources say his full aristocratic name is \"George Gordon Byron, 6th Baron Byron.\" His surname is definitely \"Byron,\" and his full name is \"George Gordon Byron.\" To be concise, I can say: \"George Gordon Byron, 6th Baron Byron,\" and mention that heâ€™s also known as Lord Byron. So my final answer will be: \"George Gordon Byron, 6th Baron Byron (better known as Lord Byron).\" That should cover everything!', type='summary_text')], type='reasoning', content=None, encrypted_content='gAAAAABpCVlkaBOzohZFdpcMKmViz6SsDgVSLE9X1FMJp0jMyunKQBDcc8PptN4DuTSj-sHyzvToMBOLeDSV52_EpI5iaQ8uNH0eFYEAfPnZT3HKUl1J46amyFUbpfgaqpB5SGaoMgjcDZLYj-oPdMW2bt5iCj61aWJOOdgELJ4AFX1JuItr59Uls-4GbdAezgIxxSEnp2_6v8PORtsOcAhfAk7YjeY8bk658nYzPe_mrqIbMBf81pO8L9-FXsAqg7yTJpt0Ro-S7QRux_RT19h2SnvTHXrnMvPZpLEsqUwY-3i-F4828LE2MCZlIC3sq15BEtxgdzQAE32S2rfStuPLXhicx1hRkIETiYNTIwoEsfbgysz9Z_fSh74crLF_PYkv650DDcDkqTB3dYQPKXyntd3VzX5bcCQ46YsLvlDxnpXa_juazhbYtvm2AheTh8FlsminKrCj2QY4ccuGqI24vRj3wcvMt89iP1h9qL-VMKlNTBDxzaeuryfrDFUgzzD745Cq_ZwEaJxL4o4T-QhZbINOReZuVCeISwGrHeXHbuIPOBfkvzG6ydMhdJE0zySHaKl4shYpF9Hq8EGqza6yKEd67_J8y4wodu-OlHitwfZO7dHrbkmBnXptNmDrQLqt_yrEId835lh_M7eLvFLPNPl_6yRICW1GTIdswg4RGMAGTWkNwLvTqTtlVbQWfdgu1CjInmd6d3e83qM-dyQCVKFmeTP0XmwTP_FCICzfIwV_XF7aFxABTF8-jDUotj49VL3F6vh3BT47gVfANnSfJC8xcfNLF3MtmZ2NjupHhykrRr2Nkj7sxzXUKEHTdQI9pFB1jxgcHTp3D6U34AJ6N9SXlvkNWGh1H1ioRT8HrkZtOVzHepzYrcknY2QAuAzTBBEWOevN65Ycehy4KDupNNUC5vTqU8bTXngB-psD6MznTpA4rV_nd3RBVaq2S6-UZWEWc0G_QKJSqqMDc1JOF8qMvMZBzRifgXk26FpLyKeJcpgMboP7TyTsy7PFREQOreBCyEGjJgQOku1D1iegmp4m1DXyg24skA4f4oowEc3NAeLqScmU8SfE-90oZ2RU3OFcOPOe1aWZXzf7HK1fLQj8NAHtG6XfWG7DAQv8nrSIxNwwrceKSmkWR8c5omLTiP7aRBFM6UCNOfDijY8quGj2b4B4i_yxEVB6LAon6epq29eZgsD36_h6en6K1fhJCpUxMQLFxAMh4GJlQosMFlD6EwFZzHZNY22ymBEiGHVNyXBmlxkSSE5lwTbehCF3xhdOKbPuT5xnERYbNMfjInvlPQYQZQgWpX7bdarsMGjiRWRuHdiTKvDqif2ge73aheeqV5XVwh7LtLAX3b1Hv-F03KeVcdU1gfqxS3uyzUQBnny-zwhLeE5izby17flZefSG0ZFo1Zh4ghrKFbK-AcPFH4YE7tu_InDMdGsB0djEDOF8uRgz2LQYNLcgLQsWGQFJ1mt7uTNIu8VGjoiGrP8zt7OIcmjqxwXypopgKgO2GvE888ABsZIzUlI7XmSUYwsr-PPM8PuQsUdDgp6ft3ETSpLG3rKlCYyTN5g19pkrDsFzlye54-Lu8rap_R0wQGgtNBleBUugWnFbcQ69EpUH7BZCQw8QYAvwLelfGUcAs-wCarjoa1g7Q3wg9fPE-QRMTaJ_A2UtID06erC5E3mbAAoJm_FlleOnidFBakbbofPTj5e0XITDKZJRYmohWFvE_4InHPYx1jrEB7c0iN29DqZDP0QMzpIfqb_LeF0Y7Wgp-ZBEL25IFNaavaNo5Y5vPq88xbqaTxU7F8wD8lQTIFDalmB5gvr3wqk1m021HPuh6Mt55ktQs8Grnu7_GpFMFM6KYCCikEARNtuXCxbuIWEGSzBzdttNqFfnlEgNxfoXtao3yvZzFjD2lASuR4qImzC42b2kvX39k2OMWyaPE2Zovg5l7K7mAfwpvbalCsXtvTqqvInCBFkXzU-MNGaGvVHBpSmxbubqnydRggHnWo2wTvdmbFFfhXO4sHtdLjZGQoeEtjpCUHv9gnq_uvkrPIFLJYXCpJUQ_BgJqFZc6vS1DQPQ1SCvXnI_T8p7-3oIvvdwUV2_fKxuY5AHTSVJOjcBmZwIl4OQT9qiIncllq_A9vE6fIZhVSzFDGsMg0bR6eTqtlv2YTid2_QF1rJadp6vq775tKtguPgsdF4gdZtyxTZvd3g1YXHl3emEqPfM2G99bFY6_pBRTxUK9Nr2hVW_ArHoOuEV96nEnLcee34JNEdQLjrl_z2EE8MMpldfKp1GzA4gUKDjmWQyWD6QC5IMWg82rYjbowoVtsLBKRw6VzO08yirR8KbXXOIEztyRcrMp-8eGZQNsVvK35jOyvM_d6spUxtrfAYvexuXBl-gZPdvrbikgXkMdPokpQDSxn7rM72KAomtzzKJPIptIO06jMYuD2oTTs0aLYMqa-eVS0eGuh8kO3uw32sEjitlQMdM_2wNFbe_x5NMq0wAQoKyaRCntHH3xWOWDqOIM_cNzxtyFnEa3LdF2t2DcFQkjU9_tOik_2BSWHigK6Qy7a0LRmBSuh11yvksXyjuRs3vwTsEIExEVmPXkgQn1WlvTRzECV0_u2dg6h2mPIxU4kWGpyXP7Jsz6-juv4VUGPDJPOiIpnk34I_x3KHrBi1LvB-RM-ZVc0jjFtg-r8rnkohST2Ec3ZUJtCO94xb7D0T-Ojm9TvbWCRpxgjprEhZPpHKOSK8KqGsLPi1mpZUsoqaST7gRZjJG7FF8uT99gH4_ha6f6cQO7QDl-qWVQ3973yV62vuR8jmNq9hv3OE74NyoDAXNrRnDVUOHVBbelrf9jLvZbcFRqFctQyHxFVVwtLg0Un_VaFl04wJP-TKKusjchuKXCuJgfc1wScqL7l-cE996PcWRYhYy49BELnPsJUPXBhsNRXC_GV5rTDdcL-2i', status=None, format='openai-responses-v1'), ResponseOutputMessage(id='msg_tmp_oidh9lxfgd', content=[ResponseOutputText(annotations=[], text='George Gordon Byron (also known as Lord Byron, 6th Baron Byron).', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')]\n",
      "INFO:code_model_950a1fbba0f64d34b8efd894fd65dfba:Last message type: message and role: assistant\n",
      "INFO:code_model_950a1fbba0f64d34b8efd894fd65dfba:Last message is a final assistant output: {'id': 'msg_tmp_oidh9lxfgd', 'content': [{'annotations': [], 'text': 'George Gordon Byron (also known as Lord Byron, 6th Baron Byron).', 'type': 'output_text', 'logprobs': None}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}\n",
      "2025/11/04 02:40:02 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - appnope (current: uninstalled, required: appnope==0.1.4; python_version >= \"3.12\" and python_version < \"4.0\" and platform_system == \"Darwin\")\n",
      " - colorama (current: uninstalled, required: colorama==0.4.6; python_version >= \"3.12\" and python_version < \"4.0\" and (sys_platform == \"win32\" or platform_system == \"Windows\"))\n",
      " - pywin32 (current: uninstalled, required: pywin32==311; python_version >= \"3.12\" and python_version < \"4.0\" and sys_platform == \"win32\")\n",
      " - waitress (current: uninstalled, required: waitress==3.0.2; python_version >= \"3.12\" and python_version < \"4.0\" and platform_system == \"Windows\")\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "2025/11/04 02:40:04 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - appnope (current: uninstalled, required: appnope==0.1.4; python_version >= \"3.12\" and python_version < \"4.0\" and platform_system == \"Darwin\")\n",
      " - colorama (current: uninstalled, required: colorama==0.4.6; python_version >= \"3.12\" and python_version < \"4.0\" and (sys_platform == \"win32\" or platform_system == \"Windows\"))\n",
      " - pywin32 (current: uninstalled, required: pywin32==311; python_version >= \"3.12\" and python_version < \"4.0\" and sys_platform == \"win32\")\n",
      " - waitress (current: uninstalled, required: waitress==3.0.2; python_version >= \"3.12\" and python_version < \"4.0\" and platform_system == \"Windows\")\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "INFO:code_model_d35adefa077c4b3e9dfd90951e98a619:Initializing ToolCallingAgentNoMemory with model: gpt-5-nano\n",
      "INFO:code_model_d35adefa077c4b3e9dfd90951e98a619:Last message type: message and role: user\n",
      "INFO:code_model_d35adefa077c4b3e9dfd90951e98a619:Calling LLM with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can call tools to get information.'}, {'status': None, 'content': 'What is the full name of poet Byron?', 'role': 'user', 'type': 'message'}]\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:code_model_d35adefa077c4b3e9dfd90951e98a619:LLM output: [ResponseReasoningItem(id='rs_017636d31b58873e016909597acc948195a446cff1f8f26cff', summary=[Summary(text='**Providing Byron\\'s full name**\\n\\nIâ€™m answering the question about the full name of the poet Byron. His full name is George Gordon Byron, and he was also known as the 6th Baron Byron. If the user is looking for the full name, Iâ€™ll definitely mention George Gordon Byron and could add the title too, if they want that. The concise response would be â€œGeorge Gordon Byron (1788â€“1824), later 6th Baron Byron,â€ stating heâ€™s commonly known as Lord Byron.**Clarifying Byron\\'s full name**\\n\\nThe user asked for the full name of the poet Byron. I want to make sure I provide a clear answer. The safest choice is to give \"George Gordon Byron\" as his full name. I could also mention that heâ€™s commonly known as Lord Byron, which is helpful context. If they want more detail, I could add that heâ€™s later known as â€œGeorge Gordon Byron, 6th Baron Byron.â€ My final response will be succinct yet informative.', type='summary_text')], type='reasoning', content=None, encrypted_content='gAAAAABpCVmCk-ooBlYTYBc4IMkxijWq5LlETTuxnAEvskuvdz9hFXoGJOZ2nMVgC2Lp8tgcv1C_az3lEszo8eLFWV_o1ez9zFL6YMSzJVvLvhOiF1syDZd3EXFxiGnWNScIO2GizFmwBH6Zuv1zHUsUkhYdfPhvDJquIj7MQKjEcyQpttIVS-JPpDwW5ydzh9pgDJFd8lWM9Jw2AxurB1tJ-L4OxOOfcZcs8xJ2gmyadOr7BWCOoP4AyszqkEfkMoPNhgh32ngwBw-eDhqxhNoJEwiFkfu2q-lDMV0hW83gbNj77onhyczGfVhEkVQRF-c9dbVHTKeiWuuWOKDc_XHYeaFTkmn-HG-Ged_GY6-sBRbLSZoNbK4AnCIaN2ARNLy3ARZxmhiFfDbyruxnuAH8EN4siMTECTK8E9Emy_u7SdwsHFHg33cUSjETdURubCZzM9FnfTJntZ7xwjuu9RwTLnbQVmfz4RUU-D_Xiop1eDV-42AbZCOmHM85lSy9z0YGkqsh78AmBHzi6jZCjVifXEy_BcaW3dZ_fcRWqt5Y9mdjrPVI8ZXejLXtmjc0AEMxd4LuHIYxhPFB4usZXgYTaOalxVnhv8RJwpyD_din3UrG48MvviCdGjoSpzAmyzNBlCKQxZM_zlu0idSfchij4S6uEH4_7S7U05pVMxlOceDH8c-4wYn3IAjejOQrOo139s1FBcz9v4xjnGnY3evqzF_bKxJd0pG95O3h5eV-8RNEfiMl0VbDj6X24P1NnuRiKqb5sRjPLFZQW2iv96CP2CB96dZZTrhJj_hbTWTIIynjsgaQy9_YkQPpp5yeN2JrXcvHk6P6VnnONyx7ZVC3z0ufhyNBY24ySphMg_nAwe7AZPIT3UQo5SNtGidUUvmZOlptfr73sfTeBs9ygYe57suL2_d_6cy1WIajpkF2WmxTXhl8eEqCsCJiU6ketJl0zt9kX8ZwMFMt7py0Rglpvx7OerxLDnv16uB7rJCz7Vb-FyibePFdqr7-VrnaMopkdS3WGecEuen3vfwjeLzOp_TLdlt8hR2pZ8LxNL9TiBdifZuxydw3y6qV9iRMnoShAcRFysCm_GnNtG2RhtSTgI_QIO_dr_NMJIqIZVIMkW40NoyEjKGvCxXhpeRxhhtrkBGjEZP28iiH1KHlSDuS_Gb0xadtEYjDP_r223Y7rImdaWTAm2QwQdNGdAGsYv7-V_6kGUZfeNr-URnXUwZgaokjhsRaJAQHhxTT76P0-9kTfCpJ82T2sdYDb6HqDXDijqTIpz28WMjXadAhh2XhLkC5Be7VjKlqXXkmApRFcfRGU5wkYBAgFrbdLd4v2H1XP5kT3tPU3uv380jWO2XQ1iWKI6vNWoGjF0qRYDRMK54V1SDaU2KYKLXikiJH-JbQauyvmG2dAfvhNFyigfA_jgV6W5CyEKq3N5jQCk00rw2UebK8htJVSJ5KxwRuvVKHl1Mvop_ZgQvyQzR9BbY-wSZOyDs1xX6llFUBgax-l9OY_7JCA5q_MHc4d9pbO3YmjLXh1PWZT3KG3gOHFm-X0JXs40EMeriIjZfOr_s5RC45r0xf5BDrIbIRs4YxjFlqKhih7hYt0g-9dehtG0fcPja_LbI48hH0dbbBCmNJwwTr2je1znxeF6XJmJboyEV6AwEULsHw8wvAKyfL84SlBUIgWcynsUFZ84rfUg9jV96905wwz_63rQVmSdFsQTzd_ZwppQr3N1tyi4Jbq7racgeby0cd8Z1wurmSDRaFmMepLGJuKaIxd4zJyfs5Ry-bzz7nzZleFzZ4ylVztPeHTuqzLGgzNLg92p6kD4izHUgZO4rS9q4EAW2BAVSiBTFiz8akcBUSTESArITUjoT8xNJYjnsvYQO0JG3zAWBv4fHmiFlfVdWe1vtqin03rh-gooUOLCiE0wdsSrWCkpyWovs5K_vwfrQMHwgHMdhz4Eey2IRjnNs0rOE425UU_pl-GJyJ5qiUq9wQkRKY6pnQfwYFE57OWJUYqc6bezzxkaGf4WCZjqTFOeP2u6E8zG1HCiSNro-NkQTTjhHxjOez2XhWW2wxQ1WGI5HlIBD4jvDQSx4vlKkFKIpUtg1fdUvYDyKcPfejVPIRqJSlzRBNu8ULphvyLLyi2yePuCeeqQVBi7epQ4mMQqvksOSVoc2NWqGrN8gRywX6j87GTtmTsO0EHYWeYjYGV3clsbNrFSdN0uaRj1plYpQhWecOi6UVc5QnBLzL-jBn60eqiZL5JRnxutK8nnyOqzkldW70XFXzGwuh5AAd4qvhSgFZF03XUAUNME6eIxyrtML_lMXM8e0XSkvGdGfcY0sPmcHK2OId6OSLCH-28VeO-dFY9VbNgKEPIyaZ1chlR9Sg7lALAKaPSThITFY5j0Lb-fVImWXJbT7Ho-iPIzokUiSeYFXU_SyFrl3INBA_jXZbIzmXg7Jwx8KPRqgO_MLa8EymU4obkZ6Hw4tm3W1RGyHYAgHMOex-ii7RzAaywP4QdYvVfXzMjGcbDaf3E7JwVwnHHxdS99mtyXZzoyprGoK9IX9-Rt6Np1v-f7JXLlhFTMW6_m8ga18Q9k8VYvsJD9WzSmojKdY8RsvA719tX8bMKHDOjgOXQtLU7Se5Pkbvycg_A6pR-pbE87VjRqItIYdrTqu1rOgoNXrbwXF1_Li2QDThoZmbkNuRfp_7XYZmNG9YpJS96bDIhnFwESiqwxDrQlVPJQLt6vHtsopzdtL0QVPFJlpkFVAzqG7nvWCsWL2P4Aoos1qDL1NXsK5DV4A-DGA0DAuHelop7EaIRhTbTAmslAclNmdoG-l5mujKMvxpkYsBvL3lSqB1MRXNL3jH08VWFFYE4azGpWoodJKylyUvhBmaKr8-MQOgOke7_eEg5Bz2kSePHt1mM1AKRd2KGh8OgJrFcz6C-LM1j3Q9nuuGWTNp4ZFIA2z_7ulFBUu2z5xHMiDs41oETDR2_YL6VVDlvfkKYOpQCxO2LS2xAihT1IHI6VZgUfcEJGs5OdPsbqaQ0xCzkMdZJQ27298FzFRMWt69Suk0pM9DzIqPfKvbfLiDlMAlR7F-iby0dklY9XUqPuYeUvOa_OVAfkHW7DHW_bRviReM7PK6Z7H7vgG8okqGUlG42SCG_edJzWvQuxHAacKwgUywLi8SUX6UfXZSN6FdWpK4mMMxW4BMWDoI2avGKJMyPc7eqpkDwZg4V-JYIae_7HuLraLceB_-PVvKbIZ6WmHvgCaOlhvtXEqccgMJHt0wHhO_tlU4EFLUjh_UCdK7fC3mP5S-HnOavrZ1X9d65k5sUwkGGdYrPt0D2v4EHmXmL9e1UscDJXgTT2kRBPOWYqUxJWAMsw1GkyTmJo9fgV4=', status=None, format='openai-responses-v1'), ResponseOutputMessage(id='msg_tmp_gd4zblbt6nq', content=[ResponseOutputText(annotations=[], text='George Gordon Byron. He is commonly known as Lord Byron, later the 6th Baron Byron.', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')]\n",
      "INFO:code_model_d35adefa077c4b3e9dfd90951e98a619:Last message type: message and role: assistant\n",
      "INFO:code_model_d35adefa077c4b3e9dfd90951e98a619:Last message is a final assistant output: {'id': 'msg_tmp_gd4zblbt6nq', 'content': [{'annotations': [], 'text': 'George Gordon Byron. He is commonly known as Lord Byron, later the 6th Baron Byron.', 'type': 'output_text', 'logprobs': None}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}\n",
      "2025/11/04 02:40:17 INFO mlflow.models.model: Found the following environment variables used during model inference: [OPENAI_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "Registered model 'workspace.default.helpful-agent-no-memory' already exists. Creating a new version of this model...\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "/mnt/e/Projekti/ml/databricks-timeseries/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Uploading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.60it/s]\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "Created version '12' of model 'workspace.default.helpful-agent-no-memory'.\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run persistent-lynx-912 at: https://dbc-7d1169bb-4536.cloud.databricks.com/ml/experiments/654634460709250/runs/f562e2712b7749fcad421a6afc9ad69e\n",
      "ðŸ§ª View experiment at: https://dbc-7d1169bb-4536.cloud.databricks.com/ml/experiments/654634460709250\n"
     ]
    }
   ],
   "source": [
    "# Timeouts on dependency collection even when given  20 minutes timeout with MLFLOW_REQUIREMENTS_INFERENCE_TIMEOUT\n",
    "!poetry env activate\n",
    "import os\n",
    "import logging\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"mlflow.utils.environment\").setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "experiment_name = f\"/Users/{os.environ['USER_EMAIL']}/agent-no-memory-{datetime.now()}\"\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except Exception as e:\n",
    "    print(f\"Experiment {experiment_name} already exists.\")\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "mlflow.end_run()  # End any existing runs if they exist\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        python_model=\"agent.py\",\n",
    "        name=\"Helpful agent without memory\",\n",
    "        input_example={\n",
    "            \"input\": [\n",
    "                {\"role\": \"user\", \"content\": \"What is the full name of poet Byron?\"}\n",
    "            ]\n",
    "        },  # Example input instead of default sample \"Hello!\"\n",
    "        registered_model_name=\"workspace.default.helpful-agent-no-memory\",\n",
    "        pip_requirements=\"requirements.txt\"  # Specify dependencies manually\n",
    "    )\n",
    "mlflow.end_run() # End the run after logging the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the downloaded model/agent - useful for model prediction debugging; model is downloaded from databricks\n",
    "# models:/ is a special MLflow URI scheme that refers to a model version registered in the MLflow Model Registry\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.models.predict(\n",
    "    model_uri=\"models:/m-763cdcbde5584da5b7caa2f47dcd960a\",\n",
    "    input_data={\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"What is the full name of poet Byron?\"}]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62520e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model locally, useful to test collection of dependencies and test predictions locally\n",
    "import mlflow\n",
    "import shutil\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "path = \"./models/helpful-agent-no-memory-model\"\n",
    "shutil.rmtree(path, ignore_errors=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"mlflow.utils.environment\").setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "experiment_name = f\"/Users/{os.environ['USER_EMAIL']}/agent-no-memory-{datetime.now()}\"\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except Exception as e:\n",
    "    print(f\"Experiment {experiment_name} already exists.\")\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "mlflow.end_run()  # End any existing runs if they exist\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.save_model(\n",
    "        path=path,\n",
    "        python_model=\"agent.py\",\n",
    "    )\n",
    "    # Upload model\n",
    "    mlflow.register_model(\n",
    "        model_uri=\"file:/mnt/e/Projekti/ml/databricks-timeseries/models/helpful-agent-no-memory-model\",\n",
    "        name=\"workspace.default.helpful-agent-no-memory\"\n",
    "    )\n",
    "mlflow.end_run()  # End the run after logging the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databricks-timeseries-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
