{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125c219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/16 00:02:39 INFO mlflow.utils.credentials: Successfully connected to MLflow hosted tracking server! Host: https://dbc-7d1169bb-4536.cloud.databricks.com.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Connect to Databricks workspace with submitted credentials or use stored credentials\n",
    "mlflow.login()\n",
    "# Set tracking URI to Databricks -  tell MLflow to send the data into Databricks Workspace\n",
    "mlflow.set_tracking_uri(\"databricks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1ce258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: poetry: command not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:code_model_e78a46b670474b4c838f92390657c221:Initializing ToolCallingAgentNoMemory with model: gpt-5-nano\n",
      "2025/11/16 00:03:10 INFO mlflow.pyfunc: Predicting on input example to validate output\n",
      "2025/11/16 00:03:10 WARNING mlflow.tracing.fluent: Failed to start span predict_stream: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:code_model_e78a46b670474b4c838f92390657c221:Last message type: message and role: user\n",
      "INFO:code_model_e78a46b670474b4c838f92390657c221:Calling LLM with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can call tools to get information.'}, {'status': None, 'content': 'What is the full name of poet Byron?', 'role': 'user', 'type': 'message'}]\n",
      "2025/11/16 00:03:11 WARNING mlflow.tracing.fluent: Failed to start span Responses: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:code_model_e78a46b670474b4c838f92390657c221:LLM output: [ResponseReasoningItem(id='rs_06cc6522f273431901691906b0370481938ee67bf9aca83f16', summary=[Summary(text='**Providing Byron\\'s full name**\\n\\nI need to answer the question: \"What is the full name of poet Byron?\" Heâ€™s commonly known as Lord Byron, but his full name is George Gordon Byron, 6th Baron Byron. Born in 1788 and passing in 1824, he was a British Romantic poet. The prompts require a clear and concise answer, so Iâ€™ll note both his name and title, emphasizing that while \"George Gordon Byron\" is his name, his full title includes \"6th Baron Byron.\"**Clarifying Byron\\'s full name**\\n\\nI can respond to the user that the full name of the poet is George Gordon Byron. He was later known as Lord Byron and held the title of 6th Baron Byron. I should provide this information concisely while still mentioning that he is recognized by both names. Since the user specifically asked for his full name, Iâ€™ll present it as \"George Gordon Byron\" and include his title for additional context.', type='summary_text')], type='reasoning', content=None, encrypted_content='gAAAAABpGQa4Su27P-2XOjni_a6ghKa8VjkrkHAJksYYuxenD8pFzVm689sTWrzJ_sDWncq8u-99783KIRRVpCNWhzSrn1j12n4yR1ThO7RcRsSY1fr8B6588jEubwCW-GNdp7t19HdnBmOenO7mKbPLUAVqeDRJwyhwMy-ok35yfHIyS1PSGHmcjV3JZlYMtHvX5nPczU6MhbHnU6oRqnT3cnZSAAlIvSoOIWOg_6XmLe_FaUMPC2CR3CRv9hALkejwyO62Y6-cDftivFwbXutJtsgSOVQP4d952_5Cnv0xRlF2_kxde1FAIJq4V7G_sIQeodznD2FnalqO-dmnDxP39mVhBXF53D7JVzjE2qMuK6aS08zQzpl4_5hEphXy4rITeU-YEUTWymJP8MzqrMcGGwFDhgqEpx9MMF8YXsNETXxlzSfRoH8Mu56j0IfEQINoF5xAZEVp62JtoBIPMDFbrD2R18bEuxeAkUAlZVefFj_fVz7Qk7wJ2cv4xhvhyTbS_MzKc5Cr970eHRUDbjnB7NtoBXBW5EIEiyNQgFluEi2xyHbCA8A8dDhk_FOY5AJcB4V4zIMi1uhiiys61kXIgFKiCcoIUG4uAabhUwWwWSmqYqC8aeWuR9d6rZw-i2xk_Kr25Th3d0o28pzQsmIb01mGp9imig26G9qC6q7ZTTMIFLC6DKOdzU1LxEB0faA2Q1OGOkd2jWtS9UOpVUIB8vWl-ZrBW_KzZbU988qEWxEzCupKpmG6eVnhRtXFqbWANWIrKs3MGfGpo17Dl8ZdbLv8KYqNGg2oW8pIOB6zEaZBapZ9fuoTQUaSewqGUcwZMKrqOjma167JQr1FIEVSFR3Dxll7G4mwBseKovx8HQLYuEgZ8tS8_ul8HX4ZzRPulCWxpRvPU3KdxXb1B5qTvsUoTIe1SfIp092GT_-0u_Xtu-DyW1FoIXrT7XUFm7kibIYaZS0Zfb7KpRRCHzNyMByClTTHZLBpGgcxYl75QDc2kYpcAmoMaSZXx15AAm5PldYrzCVT7RJU19QJUAhdRpYZXoL7EfrQ_W0Tby-qexG1Br7mG-tl6iPKrY2eYWMqGlkN_2ZXbJfTrdSEDei1IrebubZXoQrviHod-62xiPX2hyaEGj2IkcnoQ-VbjzEZmMgcczD40Ygzz167afMqK207efRYzfxmFVcjt4inPXH9WoZF0IpzKPdlWTlaZsnTpUY-pXWjxXDluFyLGV1hZhoG1sUmed95Vkk-fc1iTkunBb7_5y4l6Rf0UvFHBfN8qM_aV__1qeydNNEF2LIsWZS-_iu5lfFjCurg_XpanZhE05U8FnDneAkJ5qdrnTV3K0l2RimDQISPsXOcLqsQtlXYdJBzyz4pNwhVhapFm8MwcroCXPwJwVFzqd5vfjV8ufUBbYF_7Zujn5abRjmDXYWSoFOvjqKihh8QPp7woGavmvpjK6qb9rHieGhHvlzloLRuTocxTDdrWCuBTieM8Q0qYeom4yiVe2IjfsCZylq8Xt3xstXquOprU7NpE3fP0US_K8W2_ILtN8OOm7KMlKsbtZVh1YGMtWukYxc5Hf7T-qOCRNNWKFdf3ibJO3FPgNQ1i90WMzsWQFHpb0LqTUkcX8lBPqkETHH--2limOCX7nBKEr05kgeCdAzCtPUxWgLI2sAcXSLsH6U4vH_xFQERnz7y8SU0anQZCw9covu1Z2ODg-t4TywJaGEE_WIqUpxbhj6klJpakLSH41JFmu9B8Vm-WNBpjzL4kb7T4pO_-lHGTkVOf2StZ8wIjql0QdkClTpTXSQQxtiLNukz0EDC17W_kFMbeLTCtk6ixzLMRS5yGM-qZNzjOxueD-KGv2ph8vvtvmiyZP9kfHe3ivxTIEV-t3vW6F_uMp3058-c8z4DlN3WWxhfJPLpEg-089v-QIVWOu_NcZVoahKEVl1WH8VrEmG2LSoT8ReLRpm4tvS9_jSHAYj-YC-P947YE8Q1NIx_9hblBigDa3mQfBLySDI19JpmYO2W9xO9RJswsEYhA2C-UIlmlfEe7ej1ba9ogQuUC8cWtVO-yaDj4NWSNbD86PQd9AtffOh9e5kqur7e50fG0E0h7H0ZRznu2nXJgjgcv30feEnBO-Xsohkd-SnsOCbJ-BC03IAQZDn1Q7R1e79mDFC4MzW0e6XGtd9kxImgTagMQmhRePYiZhVUUST9Q5flU1kpjUFfvvOi_000JbihKjgHQR6ekBgBxVcxAzpk13ANbX3XbjbwgN7VYzlH_o8oZY5xcp8URavXQD8CPrP79FSJTelHTZ9Am99PH526jWNuOCNeIdgesNysZhK5wLELGOuHXePe90w7IdHqTFu5CEu0Ts2CzpO2D0b0GsmZ6SQP8e7tNKf-mqnJN-drI_VNM0QF7kJpzXtr6YR7B8DujDHXBvsdBV0dgUBJRWEQlVdNSi-Q3RAT0i-B9N4-0JClcC7xOcKx1lVYH1FVkj9LDJ7fE-gkLBlRYqADEbqk_QuAnZUfbOIUShCMcap09WcgdRR1p0Q4jN6RhY9z-8k1FhtltbihMujQbd8EK3JlBa_MjH5DSqUdon8LVRSagalOx_Wd1LGhTLybC3rm73v9U9exscYkgByTgqyIKajzZjMskmv_qgudU4NBUkIVQ1KOuQ94GaqBForEi1h-GIMfxH5Pmv28xB7Zp65Va_0V', status=None, format='openai-responses-v1'), ResponseOutputMessage(id='msg_tmp_hm60iozitq', content=[ResponseOutputText(annotations=[], text='George Gordon Byron. He is also known as Lord Byron (George Gordon Byron, 6th Baron Byron).', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')]\n",
      "INFO:code_model_e78a46b670474b4c838f92390657c221:Last message type: message and role: assistant\n",
      "INFO:code_model_e78a46b670474b4c838f92390657c221:Last message is a final assistant output: {'id': 'msg_tmp_hm60iozitq', 'content': [{'annotations': [], 'text': 'George Gordon Byron. He is also known as Lord Byron (George Gordon Byron, 6th Baron Byron).', 'type': 'output_text', 'logprobs': None}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}\n",
      "2025/11/16 00:03:40 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - appnope (current: uninstalled, required: appnope==0.1.4; python_version >= \"3.12\" and python_version < \"4.0\" and platform_system == \"Darwin\")\n",
      " - colorama (current: uninstalled, required: colorama==0.4.6; python_version >= \"3.12\" and python_version < \"4.0\" and (sys_platform == \"win32\" or platform_system == \"Windows\"))\n",
      " - pywin32 (current: uninstalled, required: pywin32==311; python_version >= \"3.12\" and python_version < \"4.0\" and sys_platform == \"win32\")\n",
      " - waitress (current: uninstalled, required: waitress==3.0.2; python_version >= \"3.12\" and python_version < \"4.0\" and platform_system == \"Windows\")\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "2025/11/16 00:03:41 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - appnope (current: uninstalled, required: appnope==0.1.4; python_version >= \"3.12\" and python_version < \"4.0\" and platform_system == \"Darwin\")\n",
      " - colorama (current: uninstalled, required: colorama==0.4.6; python_version >= \"3.12\" and python_version < \"4.0\" and (sys_platform == \"win32\" or platform_system == \"Windows\"))\n",
      " - pywin32 (current: uninstalled, required: pywin32==311; python_version >= \"3.12\" and python_version < \"4.0\" and sys_platform == \"win32\")\n",
      " - waitress (current: uninstalled, required: waitress==3.0.2; python_version >= \"3.12\" and python_version < \"4.0\" and platform_system == \"Windows\")\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "INFO:code_model_0d22449f659c4b0e94110b5e0da92586:Initializing ToolCallingAgentNoMemory with model: gpt-5-nano\n",
      "2025/11/16 00:03:41 WARNING mlflow.tracing.fluent: Failed to start span predict_stream: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n",
      "INFO:code_model_0d22449f659c4b0e94110b5e0da92586:Last message type: message and role: user\n",
      "INFO:code_model_0d22449f659c4b0e94110b5e0da92586:Calling LLM with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can call tools to get information.'}, {'status': None, 'content': 'What is the full name of poet Byron?', 'role': 'user', 'type': 'message'}]\n",
      "2025/11/16 00:03:53 WARNING mlflow.tracing.fluent: Failed to start span Responses: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:code_model_0d22449f659c4b0e94110b5e0da92586:LLM output: [ResponseReasoningItem(id='rs_088cebb0be22667f01691906d9d6648190a8423c35f329bcdb', summary=[Summary(text='**Clarifying poet Byron\\'s name**\\n\\nI need to respond to the question about the full name of the poet Byron. His full name is George Gordon Byron, and he was the 6th Baron Byron, born in 1788 and died in 1824. While the most commonly used full name is just \"George Gordon Byron,\" I can mention the additional titles if needed. However, for clarity and conciseness, I should say: \"His full name is George Gordon Byron (later known as Lord Byron, 6th Baron Byron).\"**Crafting Byron\\'s response**\\n\\nI need to respond succinctly about poet Byron. His full name is George Gordon Byron, commonly known as Lord Byron, and he was also the 6th Baron Byron. While I could mention \"George Gordon Byron, 6th Baron Byron,\" I want to keep it concise. So, a good response would be: \"George Gordon Byron (Lord Byron, 6th Baron Byron).\" I should ensure it\\'s clear yet brief, focusing on what the user wants.', type='summary_text')], type='reasoning', content=None, encrypted_content='gAAAAABpGQbgFGJlB9IcmpjU62x_wZEWjwOsxKj_jcUxxr4ANBFL7VM-VqVhypfmD-vHenHYb8GLHeOIz_GYLABgF9fPsDCMXMQgnFJsbgQatH0-IIAhYSziMx2hTD_tv5bLhhDhQ6LiY-XN3jnb090oTxamNfUu2NwY0ZQpVG2w5VXodR0xpkwTE_dXuPUDkUIhZetKKW2Lpk5aD5JLvbp0nZuFXS9pOql0mjHdqIqa2x7Jr5hE39l-K_voZ_RJydd_Yy4UzByHNjiJtBg22TQ3nEeyWcCQDdj1FVa5VMChc_RQ_pFcQWH4zi388HDtXZ4fboTX8VEZN0z66FGPp-zUBFj_S4sSHRP3VSChxsf8LYpu95ChY4zOhfEIcHTOEEIwf4vHXVA3akChEySkBpQ7WVMZRLm_dpYmr-vbp4TTutaREfb_ZgcEjxsv6DMFCTbdOiLpP1MbD_5XmpATw6v0YJuY-4AryF-7tPunkMkPobrfVIFqVmqmtZkGDyxRJsq1y7cj1wDqoS5zSS67k4Q-865U-9JjtEH6t-gbbt211UNFSLW20IJHvqWSpkxVLH6OUOh6YGG_-VX4X6xScL6P-X2edEd944bc0kq-Vg9uFOrfF1MQW8waXxIgpsQjDrYKnKHLeqlvVwEumSANPKDZMTkd13Pxyb2OipIANlnrqOdjEvdHwH7QjwfM4qRG9Ud6P1N4947kJotiraiU4xDru6UAUla4X2xwK2zOL7Ji66HW2FJPyN0bX0fGrhGDlbT4pdhGD1NUiWscEOdJWq-7TMZ1foe2z5lGJWbSgXMyyO-ezSsJvZDqIy06lM6ZFu8ySvwgoCPN4PV8PDmDb6tSHRiKySqL-8yaopSRUeyVe0ge8RGDD_7ZLhVBEDzPH_hs2g5GX1TGdzpidwMV7RgTAtFp-POMUCeZZq5Q9AUI7IJgKYbY-dgROSF8qRYGxb6pVPkme7EC59AXejdL1I9E3CETK6kR-17ibpKKgQX7F1ljhlq2XygQVpg0AKIZOA_Oirym6xPQu-qVuZH3Vzy_JtwqNUmycUtR4M07ko485qufyrj7dWP1-8KdFm0caA48HsD7e1hl7bukvyKX08lyZX7NHTfdC9Ajp__GN3cPdZRwNdeF8emmAK2A2KjKRG_NQO5sLX8ZBjNbQCcoJBprtwqmKCwDiqlbz-gLSq276zYfbbpCzcq4w8wZmAS9LnCOoME_hggkTsiq2GdxnEDOpT0hflasLtrcQrMueZfuDkr5g5EZ--Fi4T1baRdfQDWayl2Mv8eGv8ldtl6mo-o7Xo_sFKsqtFq7u59SNHudpFYZDOuYnc0m9Bu8prK-jCYN6m2vmqylRgAfCLxFFCYj2NqdW17y3esgVJzxZXmIaczrpGUXJWB5rmWY9c2SJgHkZsYyCPRbrG3z6YkYNyVB5ONDKOBjVpsACk2AhXM7QQ-4uN9ztwdu73ROR1i3vpKvWq5PPnpaKCStPW1BSmdpYTJ3PlD9NcuQd8yCoArjhqxp37KClFDTl3gHoBP12j6f5MyDuZBoOczzpd2CBsnlIFAnbv3MdnNUuX6kqXf6x-KipqlpCn7qZfVhGxl2-HsOpEe-FVqC0ekccwPp9P7XW5ifqOkhtVXI6AS209R7VwafbOCMeLymfKpDAHN0hd-oIvq6wdJERfT6Telqat_f2VGazh2OE5LCGCA1lMaPFHZT3buijSdFoeUg6AGp4UWmxckbkUuC-P8qKRf9dspfOxJBUU_Qz3PCFb4H2haONXg6Ynj__xbtxGaHuSZMlx-kAdU0ynPk58aghrrPYY8bVbj1foyG1z0byjIjGfTYZVyAHrYfu2X-P7TWdr30drOGGeQDoaWi7h2qciApnqozzYEwtBtRKK-lnKoWnFi2VGVFp3zi793R_pLVeXSp-dVkStKgS05zR3XJm9dx4eaQS6zNfaYmdggay9YVjfeEXQNKtDEHlWDKeCc2672cQVmI_zIMiyMOZBmLTovUAbPmj-5urHTNnU7QfxXZCY0zAxdLpL-2BtiF7JnW9LpoYqVi-zj7cowUQAQ_Cey-P9-5mBUSf12OthMnxO66p4Aw00YLmxpOmzk6fF5FKwreuFXibJJjYHCziUmZO6NtXRaSoh_tPRZtspvGexG2ANLliwurYbmdFOgKmKztlzT1KIYrE9CAGPQLP-2MEyBA5_xeDHWjr_oHxABzZKB75ByklMvyCk2iQ7-_1iSv0ts_owd1KLp6-WVQc9rDRsy42YhCzjPrhaG_-Mh67dwxz8qz7ShqI8onaWN_mQm_HKFVKZ1pgn1cZQr9iuWzVlgjKeAB17CR3hZzVUsmdGRa8eF80pF0pDXKaLpUwp4hlfBiVT-qPTd5jsvQT4Fki6rfWei4U7J_64cG5tQ56ylTzOPQ9inUAD6zWrA_wqVV1GikBc1_PztTr4UZYvEc0U--yapTQ6gUGULsqhSz3MY9EI9WwlOSZ6G7ZvEP96wsw_hxnZZ1kjYH3XJE0CdKZZVNmKwGup9rnqiubwhJtbsWRVvHBMdykzJOjEqC1_C2mRZgeQDUSKdGSHkdQAYVzNVebokJmtnvvoeEWGgCdY_Rd_ij4PLLplv5E4U=', status=None, format='openai-responses-v1'), ResponseOutputMessage(id='msg_tmp_ho5799x0g9b', content=[ResponseOutputText(annotations=[], text='George Gordon Byron. He is also known as Lord Byron, the 6th Baron Byron.', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')]\n",
      "INFO:code_model_0d22449f659c4b0e94110b5e0da92586:Last message type: message and role: assistant\n",
      "INFO:code_model_0d22449f659c4b0e94110b5e0da92586:Last message is a final assistant output: {'id': 'msg_tmp_ho5799x0g9b', 'content': [{'annotations': [], 'text': 'George Gordon Byron. He is also known as Lord Byron, the 6th Baron Byron.', 'type': 'output_text', 'logprobs': None}], 'role': 'assistant', 'status': 'completed', 'type': 'message'}\n",
      "2025/11/16 00:04:00 INFO mlflow.models.model: Found the following environment variables used during model inference: [OPENAI_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "Registered model 'workspace.default.helpful-agent-no-memory' already exists. Creating a new version of this model...\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "/mnt/e/Projekti/ml/databricks-timeseries/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Uploading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.50it/s]\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "Created version '13' of model 'workspace.default.helpful-agent-no-memory'.\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n",
      "INFO:databricks.sdk:loading DEFAULT profile from ~/.databrickscfg: host, token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run rambunctious-auk-74 at: https://dbc-7d1169bb-4536.cloud.databricks.com/ml/experiments/2389118857317511/runs/28345c0405144d2a8cdb261c98fa2324\n",
      "ðŸ§ª View experiment at: https://dbc-7d1169bb-4536.cloud.databricks.com/ml/experiments/2389118857317511\n"
     ]
    }
   ],
   "source": [
    "# Timeouts on dependency collection even when given  20 minutes timeout with MLFLOW_REQUIREMENTS_INFERENCE_TIMEOUT\n",
    "!poetry env activate\n",
    "import os\n",
    "import logging\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"mlflow.utils.environment\").setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "experiment_name = f\"/Users/{os.environ['USER_EMAIL']}/agent-no-memory-{datetime.now()}\"\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except Exception as e:\n",
    "    print(f\"Experiment {experiment_name} already exists.\")\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "mlflow.end_run()  # End any existing runs if they exist\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        python_model=\"agent.py\",\n",
    "        name=\"Helpful agent without memory\",\n",
    "        input_example={\n",
    "            \"input\": [\n",
    "                {\"role\": \"user\", \"content\": \"What is the full name of poet Byron?\"}\n",
    "            ]\n",
    "        },  # Example input instead of default sample \"Hello!\"\n",
    "        registered_model_name=\"workspace.default.helpful-agent-no-memory\",\n",
    "        pip_requirements=\"requirements.txt\"  # Specify dependencies manually\n",
    "    )\n",
    "mlflow.end_run() # End the run after logging the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the downloaded model/agent - useful for model prediction debugging; model is downloaded from databricks\n",
    "# models:/ is a special MLflow URI scheme that refers to a model version registered in the MLflow Model Registry\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.models.predict(\n",
    "    model_uri=\"models:/m-763cdcbde5584da5b7caa2f47dcd960a\",\n",
    "    input_data={\n",
    "        \"input\": [{\"role\": \"user\", \"content\": \"What is the full name of poet Byron?\"}]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62520e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model locally, useful to test collection of dependencies and test predictions locally\n",
    "import mlflow\n",
    "import shutil\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "path = \"./models/helpful-agent-no-memory-model\"\n",
    "shutil.rmtree(path, ignore_errors=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"mlflow.utils.environment\").setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "experiment_name = f\"/Users/{os.environ['USER_EMAIL']}/agent-no-memory-{datetime.now()}\"\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except Exception as e:\n",
    "    print(f\"Experiment {experiment_name} already exists.\")\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "mlflow.end_run()  # End any existing runs if they exist\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.save_model(\n",
    "        path=path,\n",
    "        python_model=\"agent.py\",\n",
    "    )\n",
    "    # Upload model\n",
    "    mlflow.register_model(\n",
    "        model_uri=\"file:/mnt/e/Projekti/ml/databricks-timeseries/models/helpful-agent-no-memory-model\",\n",
    "        name=\"workspace.default.helpful-agent-no-memory\"\n",
    "    )\n",
    "mlflow.end_run()  # End the run after logging the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databricks-timeseries-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
