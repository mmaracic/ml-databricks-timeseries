{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9fd170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/22 19:27:55 INFO mlflow.utils.credentials: Successfully connected to MLflow hosted tracking server! Host: https://dbc-7d1169bb-4536.cloud.databricks.com.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "# Connect to Databricks workspace with submitted credentials or use stored credentials\n",
    "mlflow.login()\n",
    "# Set tracking URI to Databricks -  tell MLflow to send the data into Databricks Workspace\n",
    "mlflow.set_tracking_uri(\"databricks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c878388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment /Users/marijo.maracic@gmail.com/test-experiment already exists.\n",
      "üèÉ View run run-2025-10-22 19:27:58.860990 at: https://dbc-7d1169bb-4536.cloud.databricks.com/ml/experiments/3044475861801323/runs/590cb7f29976470197079bc27f32d252\n",
      "üß™ View experiment at: https://dbc-7d1169bb-4536.cloud.databricks.com/ml/experiments/3044475861801323\n"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#Do not use .env file in shared databricks environment\n",
    "#https://medium.com/@generative_ai/environment-variables-setting-in-databricks-dde16e3c3888 \n",
    "load_dotenv()\n",
    "\n",
    "experiment_name = f\"/Users/{os.environ['USER_EMAIL']}/test-experiment\"\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except Exception as e:\n",
    "    print(f\"Experiment {experiment_name} already exists.\")\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=f'run-{datetime.now()}') as run:\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    mlflow.log_metric(\"metric1\", 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163bb7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "store",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "number_sold",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7cd7cead-0dac-481a-8c31-447ceb4129c3",
       "rows": [
        [
         "0",
         "2010-01-01",
         "0",
         "0",
         "801"
        ],
        [
         "1",
         "2010-01-02",
         "0",
         "0",
         "810"
        ],
        [
         "2",
         "2010-01-03",
         "0",
         "0",
         "818"
        ],
        [
         "3",
         "2010-01-04",
         "0",
         "0",
         "796"
        ],
        [
         "4",
         "2010-01-05",
         "0",
         "0",
         "808"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>number_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  store  product  number_sold\n",
       "0  2010-01-01      0        0          801\n",
       "1  2010-01-02      0        0          810\n",
       "2  2010-01-03      0        0          818\n",
       "3  2010-01-04      0        0          796\n",
       "4  2010-01-05      0        0          808"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d148bdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique (store, product) combinations: 70\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "store",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "714c0233-3bb4-49f7-954e-2a99aa8782ab",
       "rows": [
        [
         "0",
         "0",
         "0",
         "3287"
        ],
        [
         "1",
         "0",
         "1",
         "3287"
        ],
        [
         "2",
         "0",
         "2",
         "3287"
        ],
        [
         "3",
         "0",
         "3",
         "3287"
        ],
        [
         "4",
         "0",
         "4",
         "3287"
        ],
        [
         "5",
         "0",
         "5",
         "3287"
        ],
        [
         "6",
         "0",
         "6",
         "3287"
        ],
        [
         "7",
         "0",
         "7",
         "3287"
        ],
        [
         "8",
         "0",
         "8",
         "3287"
        ],
        [
         "9",
         "0",
         "9",
         "3287"
        ],
        [
         "10",
         "1",
         "0",
         "3287"
        ],
        [
         "11",
         "1",
         "1",
         "3287"
        ],
        [
         "12",
         "1",
         "2",
         "3287"
        ],
        [
         "13",
         "1",
         "3",
         "3287"
        ],
        [
         "14",
         "1",
         "4",
         "3287"
        ],
        [
         "15",
         "1",
         "5",
         "3287"
        ],
        [
         "16",
         "1",
         "6",
         "3287"
        ],
        [
         "17",
         "1",
         "7",
         "3287"
        ],
        [
         "18",
         "1",
         "8",
         "3287"
        ],
        [
         "19",
         "1",
         "9",
         "3287"
        ],
        [
         "20",
         "2",
         "0",
         "3287"
        ],
        [
         "21",
         "2",
         "1",
         "3287"
        ],
        [
         "22",
         "2",
         "2",
         "3287"
        ],
        [
         "23",
         "2",
         "3",
         "3287"
        ],
        [
         "24",
         "2",
         "4",
         "3287"
        ],
        [
         "25",
         "2",
         "5",
         "3287"
        ],
        [
         "26",
         "2",
         "6",
         "3287"
        ],
        [
         "27",
         "2",
         "7",
         "3287"
        ],
        [
         "28",
         "2",
         "8",
         "3287"
        ],
        [
         "29",
         "2",
         "9",
         "3287"
        ],
        [
         "30",
         "3",
         "0",
         "3287"
        ],
        [
         "31",
         "3",
         "1",
         "3287"
        ],
        [
         "32",
         "3",
         "2",
         "3287"
        ],
        [
         "33",
         "3",
         "3",
         "3287"
        ],
        [
         "34",
         "3",
         "4",
         "3287"
        ],
        [
         "35",
         "3",
         "5",
         "3287"
        ],
        [
         "36",
         "3",
         "6",
         "3287"
        ],
        [
         "37",
         "3",
         "7",
         "3287"
        ],
        [
         "38",
         "3",
         "8",
         "3287"
        ],
        [
         "39",
         "3",
         "9",
         "3287"
        ],
        [
         "40",
         "4",
         "0",
         "3287"
        ],
        [
         "41",
         "4",
         "1",
         "3287"
        ],
        [
         "42",
         "4",
         "2",
         "3287"
        ],
        [
         "43",
         "4",
         "3",
         "3287"
        ],
        [
         "44",
         "4",
         "4",
         "3287"
        ],
        [
         "45",
         "4",
         "5",
         "3287"
        ],
        [
         "46",
         "4",
         "6",
         "3287"
        ],
        [
         "47",
         "4",
         "7",
         "3287"
        ],
        [
         "48",
         "4",
         "8",
         "3287"
        ],
        [
         "49",
         "4",
         "9",
         "3287"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 70
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    store  product  count\n",
       "0       0        0   3287\n",
       "1       0        1   3287\n",
       "2       0        2   3287\n",
       "3       0        3   3287\n",
       "4       0        4   3287\n",
       "..    ...      ...    ...\n",
       "65      6        5   3287\n",
       "66      6        6   3287\n",
       "67      6        7   3287\n",
       "68      6        8   3287\n",
       "69      6        9   3287\n",
       "\n",
       "[70 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min rows per (store, product): 3287\n",
      "Max rows per (store, product): 3287\n"
     ]
    }
   ],
   "source": [
    "# Count unique combinations of store and product\n",
    "unique_combinations = df[['store','product']].drop_duplicates().shape[0]\n",
    "print(f\"Number of unique (store, product) combinations: {unique_combinations}\")\n",
    "\n",
    "# Count rows per (store, product) combination, sort descending\n",
    "counts = df.groupby(['store', 'product']).size().reset_index(name='count')\n",
    "counts_sorted = counts.sort_values('count', ascending=False)\n",
    "display(counts_sorted)\n",
    "\n",
    "# Show min and max counts\n",
    "min_count = counts_sorted['count'].min()\n",
    "max_count = counts_sorted['count'].max()\n",
    "print(f\"Min rows per (store, product): {min_count}\")\n",
    "print(f\"Max rows per (store, product): {max_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a170aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date: 2010-01-01\n",
      "Max date: 2018-12-31\n"
     ]
    }
   ],
   "source": [
    "# Show minimum and maximum date in the dataset\n",
    "print('Min date:', df['Date'].min())\n",
    "print('Max date:', df['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cdbc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/22 19:28:51 INFO mlflow.tracking.fluent: Experiment with name '/Users/marijo.maracic@gmail.com/timeseries-forecasting-experiment-2025-10-22 19:28:51.403488' does not exist. Creating a new experiment.\n",
      "Training ARIMA models:   0%|          | 0/70 [00:00<?, ?it/s]/home/marijo/.cache/pypoetry/virtualenvs/databricks-timeseries-ddx-2ipW-py3.12/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/marijo/.cache/pypoetry/virtualenvs/databricks-timeseries-ddx-2ipW-py3.12/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/marijo/.cache/pypoetry/virtualenvs/databricks-timeseries-ddx-2ipW-py3.12/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/marijo/.cache/pypoetry/virtualenvs/databricks-timeseries-ddx-2ipW-py3.12/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to train model for store 0, product 0: 'ARIMA' object has no attribute 'save'\n",
      "üèÉ View run 0-0 at: https://dbc-7d1169bb-4536.cloud.databricks.com/ml/experiments/1692052176608893/runs/ed780e3ac1e140cb927bb09bac7adfbf\n",
      "üß™ View experiment at: https://dbc-7d1169bb-4536.cloud.databricks.com/ml/experiments/1692052176608893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ARIMA models:   0%|          | 0/70 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#train and log models\n",
    "import mlflow\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.statsmodels import log_model\n",
    "from tqdm import tqdm\n",
    "from quality import calculate_metrics\n",
    "\n",
    "mlflow.set_experiment(f\"/Users/{os.environ['USER_EMAIL']}/timeseries-forecasting-experiment-{datetime.now()}\")\n",
    "models = {}\n",
    "groups = list(df.groupby(['store', 'product']))\n",
    "for (store, product), group in tqdm(groups, desc='Training ARIMA models'):\n",
    "    with mlflow.start_run(run_name=f'{store}-{product}') as run:\n",
    "        order = (1, 1, 1)\n",
    "        mlflow.log_param(\"store\", store)\n",
    "        mlflow.log_param(\"product\", product)\n",
    "        mlflow.log_param(\"order\", order)\n",
    "        \n",
    "        group_sorted = group.sort_values('Date')\n",
    "        group_sorted = group_sorted.set_index('Date')\n",
    "        try:\n",
    "            input = group_sorted['number_sold']\n",
    "            model = ARIMA(input, order=order)\n",
    "            fit = model.fit()\n",
    "            models[(store, product)] = fit\n",
    "            log_model(statsmodels_model=model, name=\"ARIMA\", signature=infer_signature(input))\n",
    "\n",
    "            metrics = calculate_metrics(store, product, model, input)\n",
    "            mlflow.log_metric(\"MSE\", metrics.mse)\n",
    "            mlflow.log_metric(\"MAE\", metrics.mae)\n",
    "            mlflow.log_metric(\"RMSE\", metrics.rmse)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to train model for store {store}, product {product}: {e}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cc1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics for store, product combinations in test data\n",
    "unique_combinations_test = test_df[['store','product']].drop_duplicates().shape[0]\n",
    "print(f\"Number of unique (store, product) combinations in test data: {unique_combinations_test}\")\n",
    "\n",
    "counts_test = test_df.groupby(['store', 'product']).size().reset_index(name='count')\n",
    "counts_test_sorted = counts_test.sort_values('count', ascending=False)\n",
    "display(counts_test_sorted)\n",
    "\n",
    "min_count_test = counts_test_sorted['count'].min()\n",
    "max_count_test = counts_test_sorted['count'].max()\n",
    "print(f\"Min points per (store, product) in test: {min_count_test}\")\n",
    "print(f\"Max points per (store, product) in test: {max_count_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 365 predictions for each (store, product) using trained models and compare with test data\n",
    "import numpy as np\n",
    "predictions = {}\n",
    "for key, model in models.items():\n",
    "    if model is not None:\n",
    "        try:\n",
    "            forecast = model.forecast(steps=365)\n",
    "            predictions[key] = forecast\n",
    "        except Exception as e:\n",
    "            predictions[key] = f'Error: {e}'\n",
    "    else:\n",
    "        predictions[key] = None\n",
    "\n",
    "# Compare predictions with test data and calculate error metrics\n",
    "comparison_results = []\n",
    "for (store, product), forecast in predictions.items():\n",
    "    test_points = test_df[(test_df['store'] == store) & (test_df['product'] == product)].sort_values('Date')\n",
    "    if isinstance(forecast, (list, pd.Series)) and len(test_points) > 0:\n",
    "        actual = test_points['number_sold'].values[:365]\n",
    "        pred = forecast[:len(actual)]\n",
    "        mse = np.mean((actual - pred) ** 2)\n",
    "        mae = np.mean(np.abs(actual - pred))\n",
    "        rmse = np.sqrt(mse)\n",
    "        comparison_results.append({\n",
    "            'store': store,\n",
    "            'product': product,\n",
    "            'actual': actual,\n",
    "            'predicted': pred,\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse\n",
    "        })\n",
    "\n",
    "# Sort by descending MSE\n",
    "comparison_results_sorted = sorted(comparison_results, key=lambda x: x['mse'], reverse=True)\n",
    "\n",
    "# Show best and worst MSE value\n",
    "if comparison_results_sorted:\n",
    "    best = comparison_results_sorted[-1]\n",
    "    worst = comparison_results_sorted[0]\n",
    "    print(f\"Best MSE: {best['mse']:.2f} (Store: {best['store']}, Product: {best['product']})\")\n",
    "    print(f\"Worst MSE: {worst['mse']:.2f} (Store: {worst['store']}, Product: {worst['product']})\")\n",
    "\n",
    "# Show comparison and error metrics for first few combinations (highest MSE)\n",
    "for result in comparison_results_sorted[:5]:\n",
    "    print(f\"Store: {result['store']}, Product: {result['product']}\")\n",
    "    print(\"Actual:\", result['actual'])\n",
    "    print(\"Predicted:\", result['predicted'])\n",
    "    print(f\"MSE: {result['mse']:.2f}, MAE: {result['mae']:.2f}, RMSE: {result['rmse']:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe01466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ARIMA model quality metrics on training data\n",
    "import numpy as np\n",
    "train_metrics = []\n",
    "for (store, product), model in models.items():\n",
    "    if model is not None:\n",
    "        train_points = df[(df['store'] == store) & (df['product'] == product)].sort_values('Date')\n",
    "        actual = train_points['number_sold'].values\n",
    "        pred = model.fittedvalues.values[:len(actual)]\n",
    "        mse = np.mean((actual - pred) ** 2)\n",
    "        mae = np.mean(np.abs(actual - pred))\n",
    "        rmse = np.sqrt(mse)\n",
    "        train_metrics.append({\n",
    "            'store': store,\n",
    "            'product': product,\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse\n",
    "        })\n",
    "\n",
    "# Sort by descending MSE\n",
    "train_metrics_sorted = sorted(train_metrics, key=lambda x: x['mse'], reverse=True)\n",
    "\n",
    "# Show best and worst MSE value\n",
    "if train_metrics_sorted:\n",
    "    best = train_metrics_sorted[-1]\n",
    "    worst = train_metrics_sorted[0]\n",
    "    print(f\"Best training MSE: {best['mse']:.2f} (Store: {best['store']}, Product: {best['product']})\")\n",
    "    print(f\"Worst training MSE: {worst['mse']:.2f} (Store: {worst['store']}, Product: {worst['product']})\")\n",
    "\n",
    "# Show metrics for first few combinations (highest MSE)\n",
    "for result in train_metrics_sorted[:5]:\n",
    "    print(f\"Store: {result['store']}, Product: {result['product']}\")\n",
    "    print(f\"Training MSE: {result['mse']:.2f}, MAE: {result['mae']:.2f}, RMSE: {result['rmse']:.2f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databricks-timeseries-ddx-2ipW-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
